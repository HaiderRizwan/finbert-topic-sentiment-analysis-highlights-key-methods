{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFgf0RnbvwrM"
      },
      "source": [
        "# Task 5: Fine-Tuning FinBERT for Sentiment Analysis\n",
        "\n",
        "## Overview\n",
        "This notebook implements fine-tuning of FinBERT to achieve ‚â•90% accuracy on the Financial PhraseBank dataset.\n",
        "\n",
        "**Status**: Fine-tuning is **REQUIRED** because all three methods performed below 90%:\n",
        "- FinBERT: 25.37%\n",
        "- Local LLM: 71.59%\n",
        "- RAG-Enhanced: 84.48%\n",
        "\n",
        "## Objectives\n",
        "1. Load and prepare the dataset for fine-tuning\n",
        "2. Split data into train/validation/test sets\n",
        "3. Fine-tune FinBERT model with proper hyperparameters\n",
        "4. Evaluate fine-tuned model (must achieve ‚â•90% accuracy)\n",
        "5. Save fine-tuned model and document training details\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cv9gFfTAvwrP"
      },
      "source": [
        "## Step 1: Install Required Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YTqNFWo3vwrR"
      },
      "outputs": [],
      "source": [
        "# Install required libraries\n",
        "!pip install transformers torch scikit-learn datasets -q\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-Yq1RynvwrT"
      },
      "source": [
        "## Step 2: Import Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVPeOUe6vwrT",
        "outputId": "b72c9544-ea8c-4705-aa98-68aa41d55a81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úì Libraries imported successfully!\n",
            "‚úì PyTorch version: 2.9.0+cu126\n",
            "‚úì CUDA available: True\n",
            "‚úì GPU: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    EarlyStoppingCallback\n",
        ")\n",
        "from transformers.trainer_utils import IntervalStrategy # Added import\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    precision_recall_fscore_support,\n",
        "    confusion_matrix,\n",
        "    classification_report\n",
        ")\n",
        "from sklearn.model_selection import train_test_split\n",
        "import warnings\n",
        "import time\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "print(\"‚úì Libraries imported successfully!\")\n",
        "print(f\"‚úì PyTorch version: {torch.__version__}\")\n",
        "print(f\"‚úì CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"‚úì GPU: {torch.cuda.get_device_name(0)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Wvx5Q-nvwrU"
      },
      "source": [
        "## Step 3: Load Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "5-bEv6DvvwrU",
        "outputId": "e11e8dbb-d0dc-431f-b9ac-bc465d15b7c1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0c9cbd9a-0671-4f43-a391-1c3bec2b52bf\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0c9cbd9a-0671-4f43-a391-1c3bec2b52bf\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving preprocessed_dataset.csv to preprocessed_dataset (2).csv\n",
            "\n",
            "Dataset shape: (2264, 6)\n",
            "Columns: ['sentence', 'processed_text', 'sentiment', 'token_count', 'original_length', 'processed_length']\n",
            "\n",
            "First few rows:\n",
            "                                            sentence sentiment\n",
            "0  According to Gran , the company has no plans t...   neutral\n",
            "1  For the last quarter of 2010 , Componenta 's n...  positive\n",
            "2  In the third quarter of 2010 , net sales incre...  positive\n",
            "3  Operating profit rose to EUR 13.1 mn from EUR ...  positive\n",
            "4  Operating profit totalled EUR 21.1 mn , up fro...  positive\n",
            "\n",
            "Sentiment distribution:\n",
            "sentiment\n",
            "neutral     1391\n",
            "positive     570\n",
            "negative     303\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Sentiment distribution (percentages):\n",
            "sentiment\n",
            "neutral     61.439929\n",
            "positive    25.176678\n",
            "negative    13.383392\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# For Google Colab: Upload the preprocessed_dataset.csv file\n",
        "# Click the upload button and select preprocessed_dataset.csv\n",
        "from google.colab import files\n",
        "import io\n",
        "\n",
        "# Try to load from uploaded file or from local path\n",
        "try:\n",
        "    # Try loading from uploaded file (Colab)\n",
        "    uploaded = files.upload()\n",
        "    for filename in uploaded.keys():\n",
        "        if 'preprocessed_dataset.csv' in filename:\n",
        "            df = pd.read_csv(io.BytesIO(uploaded[filename]))\n",
        "            print(f\"‚úì Loaded {filename} from upload\")\n",
        "            break\n",
        "except:\n",
        "    # Try loading from local path\n",
        "    try:\n",
        "        df = pd.read_csv('preprocessed_dataset.csv')\n",
        "        print(\"‚úì Loaded preprocessed_dataset.csv from local path\")\n",
        "    except:\n",
        "        # Try alternative paths\n",
        "        import glob\n",
        "        csv_files = glob.glob('**/preprocessed_dataset.csv', recursive=True)\n",
        "        if csv_files:\n",
        "            df = pd.read_csv(csv_files[0])\n",
        "            print(f\"‚úì Loaded from: {csv_files[0]}\")\n",
        "        else:\n",
        "            raise FileNotFoundError(\"Could not find preprocessed_dataset.csv. Please upload it.\")\n",
        "\n",
        "print(f\"\\nDataset shape: {df.shape}\")\n",
        "print(f\"Columns: {list(df.columns)}\")\n",
        "print(f\"\\nFirst few rows:\")\n",
        "print(df[['sentence', 'sentiment']].head())\n",
        "print(f\"\\nSentiment distribution:\")\n",
        "print(df['sentiment'].value_counts())\n",
        "print(f\"\\nSentiment distribution (percentages):\")\n",
        "print(df['sentiment'].value_counts(normalize=True) * 100)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-GzWD6YvwrV"
      },
      "source": [
        "## Step 4: Prepare Dataset Class for PyTorch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKzIlTNMvwrW",
        "outputId": "717c63ba-4353-4296-ba78-d7f7759ea5d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úì SentimentDataset class defined\n"
          ]
        }
      ],
      "source": [
        "class SentimentDataset(Dataset):\n",
        "    \"\"\"Custom Dataset class for sentiment analysis\"\"\"\n",
        "\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts[idx])\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        # Tokenize the text\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=self.max_length,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'labels': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "print(\"‚úì SentimentDataset class defined\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubBP81D1vwrW"
      },
      "source": [
        "## Step 5: Load FinBERT Model and Tokenizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2niA_jSvwrX",
        "outputId": "e175219f-7d20-4178-ee8d-86dacd733b67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading FinBERT model: ProsusAI/finbert\n",
            "This may take a moment on first run...\n",
            "‚úì FinBERT model loaded successfully!\n",
            "‚úì Model device: cuda\n",
            "‚úì Number of labels: 3\n",
            "‚úì Model architecture: BertForSequenceClassification\n"
          ]
        }
      ],
      "source": [
        "# Model configuration\n",
        "MODEL_NAME = \"ProsusAI/finbert\"\n",
        "NUM_LABELS = 3  # positive, neutral, negative\n",
        "MAX_LENGTH = 128\n",
        "\n",
        "print(f\"Loading FinBERT model: {MODEL_NAME}\")\n",
        "print(\"This may take a moment on first run...\")\n",
        "\n",
        "# Load tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "# Load model for sequence classification\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    num_labels=NUM_LABELS\n",
        ")\n",
        "\n",
        "# Move model to GPU if available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "print(f\"‚úì FinBERT model loaded successfully!\")\n",
        "print(f\"‚úì Model device: {device}\")\n",
        "print(f\"‚úì Number of labels: {NUM_LABELS}\")\n",
        "print(f\"‚úì Model architecture: {model.__class__.__name__}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAYt6SvOvwrX"
      },
      "source": [
        "## Step 6: Prepare Data for Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hB7cWkqBvwrX",
        "outputId": "f11657f4-bce2-490b-c020-e72d4b22a954"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total samples: 2264\n",
            "Label distribution: {'neutral': 1391, 'positive': 570, 'negative': 303}\n",
            "\n",
            "Data split:\n",
            "  Training set: 1584 samples (70.0%)\n",
            "  Validation set: 340 samples (15.0%)\n",
            "  Test set: 340 samples (15.0%)\n",
            "\n",
            "Training label distribution:\n",
            "neutral     973\n",
            "positive    399\n",
            "negative    212\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Extract sentences and sentiments\n",
        "sentences = df['sentence'].tolist()\n",
        "sentiments = df['sentiment'].tolist()\n",
        "\n",
        "# Create label mapping\n",
        "label_map = {'positive': 0, 'neutral': 1, 'negative': 2}\n",
        "reverse_label_map = {0: 'positive', 1: 'neutral', 2: 'negative'}\n",
        "\n",
        "# Convert sentiments to numeric labels\n",
        "labels = [label_map[sent] for sent in sentiments]\n",
        "\n",
        "print(f\"Total samples: {len(sentences)}\")\n",
        "print(f\"Label distribution: {pd.Series(sentiments).value_counts().to_dict()}\")\n",
        "\n",
        "# Stratified split: 70% train, 15% validation, 15% test\n",
        "# First split: 70% train, 30% temp\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    sentences, labels,\n",
        "    test_size=0.3,\n",
        "    random_state=seed,\n",
        "    stratify=labels\n",
        ")\n",
        "\n",
        "# Second split: 50% of temp (15% total) for validation, 50% (15% total) for test\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_temp, y_temp,\n",
        "    test_size=0.5,\n",
        "    random_state=seed,\n",
        "    stratify=y_temp\n",
        ")\n",
        "\n",
        "print(f\"\\nData split:\")\n",
        "print(f\"  Training set: {len(X_train)} samples ({len(X_train)/len(sentences)*100:.1f}%)\")\n",
        "print(f\"  Validation set: {len(X_val)} samples ({len(X_val)/len(sentences)*100:.1f}%)\")\n",
        "print(f\"  Test set: {len(X_test)} samples ({len(X_test)/len(sentences)*100:.1f}%)\")\n",
        "\n",
        "print(f\"\\nTraining label distribution:\")\n",
        "train_sentiments = [reverse_label_map[label] for label in y_train]\n",
        "print(pd.Series(train_sentiments).value_counts())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Q35n0-EvwrY"
      },
      "source": [
        "## Step 7: Create DataLoaders\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSQ7q9zavwrY",
        "outputId": "07a62ffb-7576-4545-a25c-7cf84b18d0d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úì DataLoaders created\n",
            "  Batch size: 16\n",
            "  Training batches: 99\n",
            "  Validation batches: 22\n",
            "  Test batches: 22\n"
          ]
        }
      ],
      "source": [
        "# Create datasets\n",
        "train_dataset = SentimentDataset(X_train, y_train, tokenizer, max_length=MAX_LENGTH)\n",
        "val_dataset = SentimentDataset(X_val, y_val, tokenizer, max_length=MAX_LENGTH)\n",
        "test_dataset = SentimentDataset(X_test, y_test, tokenizer, max_length=MAX_LENGTH)\n",
        "\n",
        "# Create data loaders\n",
        "BATCH_SIZE = 16\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "print(f\"‚úì DataLoaders created\")\n",
        "print(f\"  Batch size: {BATCH_SIZE}\")\n",
        "print(f\"  Training batches: {len(train_loader)}\")\n",
        "print(f\"  Validation batches: {len(val_loader)}\")\n",
        "print(f\"  Test batches: {len(test_loader)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Y2Jt9K1vwrY"
      },
      "source": [
        "## Step 8: Define Metrics Function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mh6qViMEvwrY",
        "outputId": "809e79a2-0440-4606-dadb-c01b2a8ad93e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úì Metrics function defined\n"
          ]
        }
      ],
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    \"\"\"Compute metrics for evaluation\"\"\"\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(labels, predictions)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "        labels, predictions, average='macro', zero_division=0\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1\n",
        "    }\n",
        "\n",
        "print(\"‚úì Metrics function defined\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Vb1kuRBvwrZ"
      },
      "source": [
        "## Step 9: Configure Training Arguments\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YeF8Iwc9vwrZ",
        "outputId": "3394ba03-9f49-4d6e-c31d-6463932bbd96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "TRAINING CONFIGURATION\n",
            "================================================================================\n",
            "Model: ProsusAI/finbert\n",
            "Epochs: 5\n",
            "Learning Rate: 2e-05\n",
            "Batch Size: 16\n",
            "Weight Decay: 0.01\n",
            "Warmup Steps: 100\n",
            "Max Length: 128\n",
            "Output Directory: ./finbert_finetuned\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# Training hyperparameters\n",
        "EPOCHS = 5\n",
        "LEARNING_RATE = 2e-5\n",
        "WEIGHT_DECAY = 0.01\n",
        "WARMUP_STEPS = 100\n",
        "\n",
        "# Create output directory for model checkpoints\n",
        "output_dir = \"./finbert_finetuned\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    num_train_epochs=EPOCHS,\n",
        "    per_device_train_batch_size=BATCH_SIZE,\n",
        "    per_device_eval_batch_size=BATCH_SIZE,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    weight_decay=WEIGHT_DECAY,\n",
        "    warmup_steps=WARMUP_STEPS,\n",
        "    logging_dir=f\"{output_dir}/logs\",\n",
        "    logging_steps=50,\n",
        "    eval_strategy=IntervalStrategy.EPOCH,  # Changed from \"epoch\"\n",
        "    save_strategy=IntervalStrategy.EPOCH,       # Changed from \"epoch\"\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    greater_is_better=True,\n",
        "    save_total_limit=3,\n",
        "    seed=seed,\n",
        "    fp16=torch.cuda.is_available(),  # Use mixed precision if GPU available\n",
        "    report_to=\"none\"  # Disable wandb/tensorboard\n",
        ")\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"TRAINING CONFIGURATION\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Model: {MODEL_NAME}\")\n",
        "print(f\"Epochs: {EPOCHS}\")\n",
        "print(f\"Learning Rate: {LEARNING_RATE}\")\n",
        "print(f\"Batch Size: {BATCH_SIZE}\")\n",
        "print(f\"Weight Decay: {WEIGHT_DECAY}\")\n",
        "print(f\"Warmup Steps: {WARMUP_STEPS}\")\n",
        "print(f\"Max Length: {MAX_LENGTH}\")\n",
        "print(f\"Output Directory: {output_dir}\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnFFyGhZvwrZ"
      },
      "source": [
        "## Step 10: Initialize Trainer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qq4KMu05vwrZ",
        "outputId": "9f6e90ad-f298-48e7-88f6-f0a0b3551166"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úì Trainer initialized successfully!\n"
          ]
        }
      ],
      "source": [
        "# Initialize Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
        ")\n",
        "\n",
        "print(\"‚úì Trainer initialized successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1RIR_7Hvwra"
      },
      "source": [
        "## Step 11: Fine-Tune the Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        },
        "id": "-vlhcXfRvwra",
        "outputId": "90f5d2bb-8f2e-433b-b607-858de915ea98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "STARTING FINE-TUNING\n",
            "================================================================================\n",
            "Training started at: 2025-11-29 22:48:39\n",
            "This may take several minutes...\n",
            "================================================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='495' max='495' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [495/495 02:21, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.879300</td>\n",
              "      <td>0.110314</td>\n",
              "      <td>0.970588</td>\n",
              "      <td>0.954465</td>\n",
              "      <td>0.962113</td>\n",
              "      <td>0.956868</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.077500</td>\n",
              "      <td>0.112210</td>\n",
              "      <td>0.970588</td>\n",
              "      <td>0.942585</td>\n",
              "      <td>0.974744</td>\n",
              "      <td>0.956574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.018100</td>\n",
              "      <td>0.072168</td>\n",
              "      <td>0.982353</td>\n",
              "      <td>0.963399</td>\n",
              "      <td>0.988104</td>\n",
              "      <td>0.974861</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.005500</td>\n",
              "      <td>0.077298</td>\n",
              "      <td>0.979412</td>\n",
              "      <td>0.964100</td>\n",
              "      <td>0.981856</td>\n",
              "      <td>0.972022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.003200</td>\n",
              "      <td>0.073755</td>\n",
              "      <td>0.979412</td>\n",
              "      <td>0.966097</td>\n",
              "      <td>0.981856</td>\n",
              "      <td>0.973367</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "FINE-TUNING COMPLETED\n",
            "================================================================================\n",
            "Training time: 2.42 minutes (145.04 seconds)\n",
            "Completed at: 2025-11-29 22:51:04\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "print(\"=\"*80)\n",
        "print(\"STARTING FINE-TUNING\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Training started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "print(f\"This may take several minutes...\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "end_time = time.time()\n",
        "training_time = end_time - start_time\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"FINE-TUNING COMPLETED\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Training time: {training_time/60:.2f} minutes ({training_time:.2f} seconds)\")\n",
        "print(f\"Completed at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "print(\"=\"*80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x12sRRN_vwra"
      },
      "source": [
        "## Step 12: Evaluate on Validation Set\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "mBxmGYy1vwra",
        "outputId": "73f5c6b9-a185-4885-d133-4235c67ee41d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "VALIDATION SET EVALUATION\n",
            "================================================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [22/22 00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Validation Metrics:\n",
            "  Accuracy: 0.9824 (98.24%)\n",
            "  Precision: 0.9634\n",
            "  Recall: 0.9881\n",
            "  F1-Score: 0.9749\n",
            "\n",
            "‚úÖ SUCCESS! Validation accuracy ‚â• 90%: 98.24%\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "print(\"=\"*80)\n",
        "print(\"VALIDATION SET EVALUATION\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Evaluate on validation set\n",
        "val_results = trainer.evaluate(eval_dataset=val_dataset)\n",
        "\n",
        "print(f\"\\nValidation Metrics:\")\n",
        "print(f\"  Accuracy: {val_results['eval_accuracy']:.4f} ({val_results['eval_accuracy']*100:.2f}%)\")\n",
        "print(f\"  Precision: {val_results['eval_precision']:.4f}\")\n",
        "print(f\"  Recall: {val_results['eval_recall']:.4f}\")\n",
        "print(f\"  F1-Score: {val_results['eval_f1']:.4f}\")\n",
        "\n",
        "if val_results['eval_accuracy'] >= 0.90:\n",
        "    print(f\"\\n‚úÖ SUCCESS! Validation accuracy ‚â• 90%: {val_results['eval_accuracy']*100:.2f}%\")\n",
        "else:\n",
        "    print(f\"\\n‚ö†Ô∏è Validation accuracy below 90%: {val_results['eval_accuracy']*100:.2f}%\")\n",
        "print(\"=\"*80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cC2C1hWwvwra"
      },
      "source": [
        "## Step 13: Evaluate on Test Set\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "FfIpQPENvwrb",
        "outputId": "a20a7296-3307-40df-8b2e-ec79452c0ed5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "TEST SET EVALUATION\n",
            "================================================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='44' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [22/22 00:43]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test Set Metrics:\n",
            "  Accuracy: 0.9765 (97.65%)\n",
            "  Precision: 0.9765\n",
            "  Recall: 0.9536\n",
            "  F1-Score: 0.9639\n",
            "\n",
            "================================================================================\n",
            "üéâ SUCCESS! Fine-tuned model achieved ‚â•90% accuracy!\n",
            "   Test Accuracy: 97.65%\n",
            "================================================================================\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "print(\"=\"*80)\n",
        "print(\"TEST SET EVALUATION\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Evaluate on test set\n",
        "test_results = trainer.evaluate(eval_dataset=test_dataset)\n",
        "\n",
        "print(f\"\\nTest Set Metrics:\")\n",
        "print(f\"  Accuracy: {test_results['eval_accuracy']:.4f} ({test_results['eval_accuracy']*100:.2f}%)\")\n",
        "print(f\"  Precision: {test_results['eval_precision']:.4f}\")\n",
        "print(f\"  Recall: {test_results['eval_recall']:.4f}\")\n",
        "print(f\"  F1-Score: {test_results['eval_f1']:.4f}\")\n",
        "\n",
        "# Check if we achieved ‚â•90% accuracy\n",
        "if test_results['eval_accuracy'] >= 0.90:\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"üéâ SUCCESS! Fine-tuned model achieved ‚â•90% accuracy!\")\n",
        "    print(f\"   Test Accuracy: {test_results['eval_accuracy']*100:.2f}%\")\n",
        "    print(f\"{'='*80}\")\n",
        "else:\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"‚ö†Ô∏è WARNING: Test accuracy is below 90%\")\n",
        "    print(f\"   Test Accuracy: {test_results['eval_accuracy']*100:.2f}%\")\n",
        "    print(f\"   Consider increasing epochs or adjusting hyperparameters\")\n",
        "    print(f\"{'='*80}\")\n",
        "print(\"=\"*80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ankEnL6vwrb"
      },
      "source": [
        "## Step 14: Detailed Test Set Evaluation with Confusion Matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 798
        },
        "id": "fhpnZR2dvwrb",
        "outputId": "aee1f992-2d0a-4368-aaa2-b8c96b6adf74"
      },
      "outputs": [
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "DETAILED TEST SET EVALUATION\n",
            "================================================================================\n",
            "\n",
            "Overall Metrics:\n",
            "  Accuracy: 0.9765 (97.65%)\n",
            "  Macro Precision: 0.9765\n",
            "  Macro Recall: 0.9536\n",
            "  Macro F1-Score: 0.9639\n",
            "\n",
            "Per-Class Metrics:\n",
            "\n",
            "  POSITIVE:\n",
            "    Precision: 0.9438\n",
            "    Recall: 0.9767\n",
            "    F1-Score: 0.9600\n",
            "\n",
            "  NEUTRAL:\n",
            "    Precision: 0.9858\n",
            "    Recall: 0.9952\n",
            "    F1-Score: 0.9905\n",
            "\n",
            "  NEGATIVE:\n",
            "    Precision: 1.0000\n",
            "    Recall: 0.8889\n",
            "    F1-Score: 0.9412\n",
            "\n",
            "Confusion Matrix:\n",
            "          positive  neutral  negative\n",
            "positive        84        2         0\n",
            "neutral          1      208         0\n",
            "negative         4        1        40\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    positive     0.9438    0.9767    0.9600        86\n",
            "     neutral     0.9858    0.9952    0.9905       209\n",
            "    negative     1.0000    0.8889    0.9412        45\n",
            "\n",
            "    accuracy                         0.9765       340\n",
            "   macro avg     0.9765    0.9536    0.9639       340\n",
            "weighted avg     0.9770    0.9765    0.9762       340\n",
            "\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# Get predictions on test set\n",
        "predictions = trainer.predict(test_dataset)\n",
        "y_pred = np.argmax(predictions.predictions, axis=1)\n",
        "y_true = predictions.label_ids\n",
        "\n",
        "# Calculate detailed metrics\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "    y_true, y_pred, average=None, labels=[0, 1, 2], zero_division=0\n",
        ")\n",
        "macro_precision, macro_recall, macro_f1, _ = precision_recall_fscore_support(\n",
        "    y_true, y_pred, average='macro', zero_division=0\n",
        ")\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred, labels=[0, 1, 2])\n",
        "cm_df = pd.DataFrame(\n",
        "    cm,\n",
        "    index=['positive', 'neutral', 'negative'],\n",
        "    columns=['positive', 'neutral', 'negative']\n",
        ")\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"DETAILED TEST SET EVALUATION\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(f\"\\nOverall Metrics:\")\n",
        "print(f\"  Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
        "print(f\"  Macro Precision: {macro_precision:.4f}\")\n",
        "print(f\"  Macro Recall: {macro_recall:.4f}\")\n",
        "print(f\"  Macro F1-Score: {macro_f1:.4f}\")\n",
        "\n",
        "print(f\"\\nPer-Class Metrics:\")\n",
        "class_names = ['positive', 'neutral', 'negative']\n",
        "for i, class_name in enumerate(class_names):\n",
        "    print(f\"\\n  {class_name.upper()}:\")\n",
        "    print(f\"    Precision: {precision[i]:.4f}\")\n",
        "    print(f\"    Recall: {recall[i]:.4f}\")\n",
        "    print(f\"    F1-Score: {f1[i]:.4f}\")\n",
        "\n",
        "print(f\"\\nConfusion Matrix:\")\n",
        "print(cm_df)\n",
        "\n",
        "print(f\"\\nClassification Report:\")\n",
        "print(classification_report(\n",
        "    y_true, y_pred,\n",
        "    target_names=['positive', 'neutral', 'negative'],\n",
        "    digits=4\n",
        "))\n",
        "\n",
        "print(\"=\"*80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qMBxNgGvwrb"
      },
      "source": [
        "## Step 15: Save Fine-Tuned Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuadNrs4vwrb",
        "outputId": "7bccaa89-77c7-45ca-8558-593db61deca5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úì Fine-tuned model saved to: ./finbert_finetuned/final_model\n",
            "‚úì Model and tokenizer saved successfully!\n"
          ]
        }
      ],
      "source": [
        "# Save the fine-tuned model\n",
        "final_model_dir = f\"{output_dir}/final_model\"\n",
        "os.makedirs(final_model_dir, exist_ok=True)\n",
        "\n",
        "trainer.save_model(final_model_dir)\n",
        "tokenizer.save_pretrained(final_model_dir)\n",
        "\n",
        "print(f\"‚úì Fine-tuned model saved to: {final_model_dir}\")\n",
        "print(f\"‚úì Model and tokenizer saved successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hzfc0mF6vwrb"
      },
      "source": [
        "## Step 16: Save Training Results and Metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4x5DwWopvwrc",
        "outputId": "f63ca208-878c-4d97-bbfb-56a84656a0fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úì Training results saved to: finbert_finetuning_results.csv\n",
            "‚úì Test predictions saved to: finbert_finetuned_test_predictions.csv\n",
            "‚úì Confusion matrix saved to: finbert_finetuned_confusion_matrix.csv\n",
            "\n",
            "================================================================================\n",
            "TRAINING SUMMARY\n",
            "================================================================================\n",
            "\n",
            "Training Parameters:\n",
            "  Model: ProsusAI/finbert\n",
            "  Epochs: 5\n",
            "  Learning Rate: 2e-05\n",
            "  Batch Size: 16\n",
            "  Weight Decay: 0.01\n",
            "  Warmup Steps: 100\n",
            "  Max Length: 128\n",
            "  Training Time (minutes): 2.42\n",
            "  Training Time (seconds): 145.04\n",
            "  Random Seed: 42\n",
            "\n",
            "Validation Metrics:\n",
            "  Accuracy: 0.9824\n",
            "  Precision: 0.9634\n",
            "  Recall: 0.9881\n",
            "  F1-Score: 0.9749\n",
            "\n",
            "Test Metrics:\n",
            "  Accuracy: 0.9765\n",
            "  Precision: 0.9765\n",
            "  Recall: 0.9536\n",
            "  F1-Score: 0.9639\n",
            "\n",
            "Per-Class Test Metrics:\n",
            "  Positive Precision: 0.9438\n",
            "  Positive Recall: 0.9767\n",
            "  Positive F1: 0.96\n",
            "  Neutral Precision: 0.9858\n",
            "  Neutral Recall: 0.9952\n",
            "  Neutral F1: 0.9905\n",
            "  Negative Precision: 1.0\n",
            "  Negative Recall: 0.8889\n",
            "  Negative F1: 0.9412\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# Create results summary\n",
        "results_summary = {\n",
        "    'Training Parameters': {\n",
        "        'Model': MODEL_NAME,\n",
        "        'Epochs': EPOCHS,\n",
        "        'Learning Rate': LEARNING_RATE,\n",
        "        'Batch Size': BATCH_SIZE,\n",
        "        'Weight Decay': WEIGHT_DECAY,\n",
        "        'Warmup Steps': WARMUP_STEPS,\n",
        "        'Max Length': MAX_LENGTH,\n",
        "        'Training Time (minutes)': round(training_time / 60, 2),\n",
        "        'Training Time (seconds)': round(training_time, 2),\n",
        "        'Random Seed': seed\n",
        "    },\n",
        "    'Validation Metrics': {\n",
        "        'Accuracy': round(val_results['eval_accuracy'], 4),\n",
        "        'Precision': round(val_results['eval_precision'], 4),\n",
        "        'Recall': round(val_results['eval_recall'], 4),\n",
        "        'F1-Score': round(val_results['eval_f1'], 4)\n",
        "    },\n",
        "    'Test Metrics': {\n",
        "        'Accuracy': round(test_results['eval_accuracy'], 4),\n",
        "        'Precision': round(macro_precision, 4),\n",
        "        'Recall': round(macro_recall, 4),\n",
        "        'F1-Score': round(macro_f1, 4)\n",
        "    },\n",
        "    'Per-Class Test Metrics': {\n",
        "        'Positive Precision': round(precision[0], 4),\n",
        "        'Positive Recall': round(recall[0], 4),\n",
        "        'Positive F1': round(f1[0], 4),\n",
        "        'Neutral Precision': round(precision[1], 4),\n",
        "        'Neutral Recall': round(recall[1], 4),\n",
        "        'Neutral F1': round(f1[1], 4),\n",
        "        'Negative Precision': round(precision[2], 4),\n",
        "        'Negative Recall': round(recall[2], 4),\n",
        "        'Negative F1': round(f1[2], 4)\n",
        "    }\n",
        "}\n",
        "\n",
        "# Save to CSV\n",
        "results_df = pd.DataFrame([\n",
        "    {\n",
        "        'metric': key,\n",
        "        'value': value\n",
        "    }\n",
        "    for category, metrics in results_summary.items()\n",
        "    for key, value in metrics.items()\n",
        "])\n",
        "\n",
        "results_df.to_csv('finbert_finetuning_results.csv', index=False)\n",
        "print(\"‚úì Training results saved to: finbert_finetuning_results.csv\")\n",
        "\n",
        "# Save test predictions\n",
        "test_predictions_df = pd.DataFrame({\n",
        "    'sentence': X_test,\n",
        "    'true_label': [reverse_label_map[label] for label in y_test],\n",
        "    'predicted_label': [reverse_label_map[label] for label in y_pred],\n",
        "    'true_label_numeric': y_test,\n",
        "    'predicted_label_numeric': y_pred,\n",
        "    'is_correct': (y_test == y_pred)\n",
        "})\n",
        "\n",
        "test_predictions_df.to_csv('finbert_finetuned_test_predictions.csv', index=False)\n",
        "print(\"‚úì Test predictions saved to: finbert_finetuned_test_predictions.csv\")\n",
        "\n",
        "# Save confusion matrix\n",
        "cm_df.to_csv('finbert_finetuned_confusion_matrix.csv')\n",
        "print(\"‚úì Confusion matrix saved to: finbert_finetuned_confusion_matrix.csv\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"TRAINING SUMMARY\")\n",
        "print(\"=\"*80)\n",
        "for category, metrics in results_summary.items():\n",
        "    print(f\"\\n{category}:\")\n",
        "    for key, value in metrics.items():\n",
        "        print(f\"  {key}: {value}\")\n",
        "print(\"=\"*80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxoYmGoLvwrc"
      },
      "source": [
        "## Step 17: Download Results (Google Colab)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "TcOLA8lcvwrc",
        "outputId": "9dc76237-df63-4072-ceec-6a521994604b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading results files...\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_71eb24d6-ea91-497e-ba04-f334f625d8a8\", \"finbert_finetuning_results.csv\", 526)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_8306246b-a42b-4403-be96-b4f558bbc3cd\", \"finbert_finetuned_test_predictions.csv\", 51102)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_d29d8728-2dd4-4b90-995b-c4555d3c0881\", \"finbert_finetuned_confusion_matrix.csv\", 75)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "‚úì All result files downloaded!\n"
          ]
        }
      ],
      "source": [
        "# For Google Colab: Download results\n",
        "try:\n",
        "    from google.colab import files\n",
        "\n",
        "    print(\"Downloading results files...\")\n",
        "    files.download('finbert_finetuning_results.csv')\n",
        "    files.download('finbert_finetuned_test_predictions.csv')\n",
        "    files.download('finbert_finetuned_confusion_matrix.csv')\n",
        "    print(\"\\n‚úì All result files downloaded!\")\n",
        "except:\n",
        "    print(\"Not running in Google Colab. Files are saved locally.\")\n",
        "    print(\"Files saved:\")\n",
        "    print(\"  - finbert_finetuning_results.csv\")\n",
        "    print(\"  - finbert_finetuned_test_predictions.csv\")\n",
        "    print(\"  - finbert_finetuned_confusion_matrix.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-MOx1wzvwrd"
      },
      "source": [
        "## Step 18: Compare with Original FinBERT Performance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxK27oudvwrd",
        "outputId": "4bfd0d89-3978-49bc-96e7-b9cd8b47f671"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "comparison_metrics_summary.csv not found. Skipping comparison.\n"
          ]
        }
      ],
      "source": [
        "# Load original FinBERT results if available\n",
        "try:\n",
        "    original_results = pd.read_csv('comparison_metrics_summary.csv')\n",
        "    finbert_original = original_results[original_results['Method'] == 'FinBERT']\n",
        "\n",
        "    if not finbert_original.empty:\n",
        "        original_accuracy = finbert_original['Accuracy'].values[0]\n",
        "        fine_tuned_accuracy = test_results['eval_accuracy']\n",
        "\n",
        "        improvement = fine_tuned_accuracy - original_accuracy\n",
        "\n",
        "        print(\"=\"*80)\n",
        "        print(\"PERFORMANCE COMPARISON: ORIGINAL vs FINE-TUNED\")\n",
        "        print(\"=\"*80)\n",
        "        print(f\"\\nOriginal FinBERT Accuracy: {original_accuracy:.4f} ({original_accuracy*100:.2f}%)\")\n",
        "        print(f\"Fine-Tuned FinBERT Accuracy: {fine_tuned_accuracy:.4f} ({fine_tuned_accuracy*100:.2f}%)\")\n",
        "        print(f\"Improvement: {improvement:.4f} ({improvement*100:.2f} percentage points)\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        if fine_tuned_accuracy >= 0.90:\n",
        "            print(\"\\n‚úÖ SUCCESS: Fine-tuning achieved the ‚â•90% accuracy requirement!\")\n",
        "        else:\n",
        "            print(\"\\n‚ö†Ô∏è Fine-tuning improved performance but did not reach 90%.\")\n",
        "            print(\"   Consider:\")\n",
        "            print(\"   - Increasing number of epochs\")\n",
        "            print(\"   - Adjusting learning rate\")\n",
        "            print(\"   - Using different batch size\")\n",
        "    else:\n",
        "        print(\"Original FinBERT results not found in comparison_metrics_summary.csv\")\n",
        "except FileNotFoundError:\n",
        "    print(\"comparison_metrics_summary.csv not found. Skipping comparison.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading comparison: {e}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
